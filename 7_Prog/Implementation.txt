Rename qvalue_old to qvalue and qvalue to qvalue2
Alpha reduce with time ??? -> not necessarily because test convergence
Use general fixed point not the other one ???
Why SFS Q no more negatif ???
Check were to do update_min_state???

================================================================================
================================================================================
================================================================================

TIMESLICE
=========
sched_slice()                                           smart.c
        __sched_period()                                smart.c

Modified, return a constant timeslice CONFIG_SCHED_SFS_TIMESLICE no more
          __sched_period()

RQ INIT
=======

sched_init()                                            core.c
        for_each_possible_cpu() ->
                init_cfs_rq()                           smart.c
        init_synch_point()

Modified, Initialize the different factors and weights used by the AI and
          initialize the list that store the entity

CREATE NEW PROCESS
==================

kernel_thread()                                         fork.c
  do_fork()

do_fork()                                               fork.c
  _do_fork()
          copy_process()
                          dup_task_struct()       -> create the task
                          sched_fork()            core.c
          wake_up_new_task()                      core.c
                  activate_task()                 core.c

sched_fork()                                      core.c -> set rq of se
        __sched_fork()                            -> set sched_entity
        __set_task_cpu()
                set_task_rq()
        task_fork_smart()                         smart.c
                init_aistats()
                if curr -> update_curr
                place_entity()                    TODO
                normalize state

Modified, initialize the aistats structure of the new state, give the state
          of the parent process and normalize the state

ADD TASK IN QUEUE
=================

activate_task()                                                 core.c
        enqueue_task()
                enqueue_task_smart()                            smart.c
                        enqueue_entity()                        -> initialise vruntime of the process
                                if curr -> normalize
                                update_curr()
                                if !curr & !sleep -> normalize
                                if !state_used -> add_aistats() NOTE: Done in __enqueue_entity
                                if !curr -> __enqueue_entity()     -> entity not in rq
                                se->on_rq = 1

Modified,

REMOVE TASK QUEUE
=================

deactivate_task()                                               core.c
        dequeue_task()
                dequeue_task_smart()                            smart.c
                        dequeue_entity()
                                update_curr()
                                if !state_used -> remove_aistats()  -> entity still in rq NOTE: Done in __dequeue_entity
                                if !curr -> __dequeue_entity()
                                if !sleep -> Normalize state
                                se->on_rq = 0
                        set_next_buddy()

QUESTION: What call deactivate_task() ?

When migrating process:
detach_task()
        deactivate_task()

When scheduling, if !preempt && task not running (TASK_RUNNING = 0) and
                    !signal_pending_state(prev->state, prev)
__schedule()
        deactivate_task()

signal_pending_state(prev->state, prev)
        return 0 if state not (TASK_INTERRUPTIBLE | TASK_WAKEKILL)
        return 0 if TASK_INTERRUPTIBLE and signal not yet received

Modified,

UPDATE CURRENT ENTITY STATE AND RUNQUEUE STATE
==============================================

scheduler_tick()                                                core.c
        task_tick_smart()                                       smart.c
                entity_tick()
                        update_curr()
                                update_aistats()
                                update_state()
                                update_rewards()
                        resched_curr()

hrtick_start_fair()                                             smart.c
        sched_slice()
        hrtick_start() -> start time slice                      core.c

hrtick -> after finishing timeslice                             core.c
        task_tick_smart()                                       smart.c



Modified, update the state of the entity and the runqueue and set schedul
          flag

SELECT NEW PROCESS
==================

resched_curr()  -> set TIF_NEED_RESCHED

schedule()                                                      core.c
        __schedule()
                pick_next_task()
                        pick_next_task_smart()                  smart.c
                                update_weights()
                                if curr->on_rq -> update_curr()
                                else curr = NULL
                                pick_next_entity()
                                        update_next()

                		put_prev_entity()
                                        if still runnable
                                                update_curr()
                                                _enqueue_entity()

                                set_next_entity()
                                        _dequeue_entity()

Modified, Calculate the utility of the next task and select it to run next

/!\ When selecting new process, remove_aistats and add_aistats are not called

SEMAPHORE and READ/WRITE SEM
============================

down()                                                          semaphore.c
        __down()
                __down_common()
                        __set_current_state(TASK_UNINTERRUPTIBLE)
                        list_add_tail(wait_list)
                        block_count++
                        schedule_timeout()                      timer.c
                                schedule()                      core.c
        lock_count++

NOTE: same for down_interruptible() down_killable() down_timeout()
NOTE: not for down_trylock() -> no wait

down_read()                                                     rwsem.c
        __down_read()
                __down_read_common()                            rwsem-spinlock.c
                        block_count++
                        list_add_tail(wait_list)
                        schedule()                              core.c
        lock_count++

NOTE: same for down_read_killable() down_write() down_write_killable()
NOTE: not for down_read_trylock() and down_write_trylock() -> no wait

up()                                                            semaphore.c
        __up()
                list_first_entry(wait_list)
                wake_up_process()                               core.c

up_read()                                                       rwsem.c
        __up_read()                                             rwsem-spinlock.c
                __rwsem_wake_one_writer()
                        list_entry()
                wake_up_process()

up_write()                                                      rwsem.c
        __up_write()                                            rwsem-spinlock.c
                __rwsem_do_wake()
                         list_entry()
                wkae_up_process()

Modified, add lock_count++ and block_count++

MUTEX
=====

NOTE: slowpath == sleep if fast path doesn't work

mutex_lock()                                                    mutex.c
        __mutex_lock_slowpath()
                __mutex_lock()
                        __mutex_lock_common()
                                list_add_tail(waiter.list)
                                block_count++
        lock_count++

NOTE: same for mutex_lock_interruptible() mutex_killable()
NOTE: not for mutex_trylock()

mutex_unlock()                                                    mutex.c
        __mutex_unlock_slowpath()
                list_first_entry()
                wake_up_add()
                wake_up_q()

Modified, add lock_count++ and block_count++

SPIN-LOCK
=========

spin_lock()                                                     spinlock.h
        raw_spin_lock()
                _raw_spin_lock()                                spinlock.c
                        __raw_spin_lock()                       spinlock_api_smp.h
                                do_raw_spin_lock()              spinlock_debug.c

NOTE: same for spin_lock_irqsave() spin_lock_bh() write_lock() read_lock()

spin_unlock()                                                   spinlock.h
        raw_spin_unlock()
                __raw_spin_unlock()                             spinlock_api_smp.h
                        do_raw_spin_unlock()                    spinlock_debug.c

NOTE: same for spin_unlock_irqrestore() spin_unlock_bh() write_unlock() read_unlock()

Modified, None

SLEEP
=====

udelay()        -> busy_wait_loop

usleep_range()                                          timer.c
        sleep_count++
        __set_current_state(TASK_UNINTERRUPTIBLE)
        schedule_hrtimeout_range()                      hrtimer.c
                ...
                        enqueue_hrtimer()
                                timerqueue_add()        timerqueue.c
                schedule()


        remove_hrtimer                                  hrtimer.c
                timerqueue_del                          timerqueue.c

msleep()                                                timer.c
        sleep_count++
        schedule_timeout_uninterruptible()
                __set_current_state(TASK_UNINTERRUPTIBLE)
        	schedule_timeout(timeout)

msleep_interruptible()                                  timer.c
        sleep_count++
        schedule_timeout_interruptible()
                __set_current_state(TASK_INTERRUPTIBLE)
                schedule_timeout(timeout)

schedule_timeout() -> callback function process_timeout
         process_timeout()                              timer.c
                wake_up_process()                       core.c

Modified, add sleep_count++

WAKE UP
=======

wake_up_process()                                               core.c
        try_to_wake_up()
                ttwu_remote() if p->on_rq
                        ttwu_do_wakeup()
                                p->state = TASK_RUNNING

                ttwu_queue()
                        ttwu_do_activate()
                                ttwu_activate()
                                        activate_task()
                                ttwu_do_wakeup()
                                        p->state = TASK_RUNNING

Modified, None

KILL
====

do_exit()                                               exit.c
        set_current_state(TASK_UNINTERRUPTIBLE)
        schedule()
                __schedule()
                        deactivate_task()

do_group_exit()
        do_exit()

Modified, None

YIELD
=====

yield()                                                 core.c
        do_sched_yield()
                yield_task_fair()                       smart.c
                        update_curr()
                        set_skip_buddy()
                schedule()                              core.c

yield_to()                                              core.c
        yield_to_task_fair()                            smart.c
                yield_task_fair()

Modified, None

-------

put_prev_task_fair()                                    smart.c
        put_prev_entity()

set_curr_task_fair()                                    smart.c
        set_next_entity()

Modified, None

-------

DETACH/ATTACH_TASK_CFS_RQ
==========================
detach_task_cfs_rq()
        detach_entity_cfs_rq
                update_load_avg()
                detach_entity_load_avg()
                update_tg_load_avg()
                propagate_entity_cfs_rq()


static void remove_aistats(struct cfs_rq *cfs_rq, struct sched_entity *old)
static void add_aistats(struct cfs_rq *cfs_rq, struct sched_entity *new)

TODO:   . Initialize AI in runqueue                    -> init_cfs_rq()                OK
        . Initialize sched_entity in new process       -> task_fork_smart()            OK
        . Update environement when deleting a task     -> dequeue_entity()             OK
        . Update environement when adding a task       -> enqueue_entity()             OK
        . Change group                                                                 OK
                -> switched_from() & task_change_group()
                => detach_task_cfs_rq & attach_task_cfs_rq
        . Calculate the utility of the next task       -> pick_next_task_smart()       OK
        . Update the environment                       -> update_curr()                OK
                - creating      OK
                - deleting      OK
                - sleeping      OK
                - blocking      OK
                - scheduling    OK
                - wake-up       OK
        . Set attributes with macro:
                scheduled_count                         -> smart.c      OK
                        pick_next_task_smart()

                runtime_sum                             -> smart.c      OK
                        update_aistats()

                state                                   -> smart.c      OK
                        update_state()
                        enqueue_entity()
                        dequeue_entity()
                        task_fork_smart

                sleep_count                             -> timer.c      OK
                        usleep_range()
                        msleep()
                        msleep_interruptible()
                        yield_task_smart()

                lock_count
                        down()                          -> semaphore.c  OK
                        down_interruptible()
                        down_killable()
                        down_trylock()
                        down_timeout()

                        down_read()                     -> rwsem.c      OK
                        down_read_killable()
                        down_read_trylock()

                        down_write()                    -> rwsem.c      OK
                        down_write_killable()
                        down_write_trylock()

                        mutex_lock()                    -> mutex.c      OK
                        mutex_lock_interruptible()
                        mutex_lock_killable()
                        mutex_trylock()

                block_count, only the added to the wait list            OK
                        __down_common()                 -> semaphore.c
                        __down_read_common()            -> rwsem-spinlock.c
                        __down_write_common()
                        __mutex_lock_common()           -> mutex.c

        . Average, Calcul, Fixed Point, Overflow                        OK

                update_rewards()        OK
                update_aistats()        OK
                update_weights()        OK
                update_next()           OK

                add(a, b, ta, tb) 	 a + b
                sub(a, b, t1, t2)  	 a - b
                mul(a, b, t1, t2)	(a * b) >> Q
                div(a, b, t1, t2)	(a << Q) / b

                Type:
                u32     ->      0 to 4,294,967,295
                s32     ->      -2,147,483,648 to 2,147,483,647
                u64     ->      0 to 18,446,744e12
                s64     ->      -9,223,372e12 to 9,223,372e12

                What to scale:
                x avg_runtime   x alpha         x w_load        x rewards
                x avg_block     x gamma         x w_avg_block   x ut
                x avg_sleep     x q_value       x w_avg_sleep   x ut_sum
                x avg_lock      x old_q_value   x w_avg_lock

                Type definition: all s64
                - alpha                         - scheduled_count
                - gamma                         - state
                - w_load                        - old_state
                - w_avg_block
                - w_avg_sleep                   - avg_runtime
                - w_avg_lock                    - runtime_sum
                - state                         - avg_block
                - q_value                       - block_count
                - old_q_value                   - avg_sleep
                - ut_sum                        - sleep_count
                - update                        - avg_lock
                - rewards                       - lock_count
                - min_start_state               - di
                - min_state                     - ut

                overflow:
                        scheduled_count
                        runtime_sum
                        block_count
                        sleep_count
                        lock_count

        . place_entity()                        OK
        . Remove everythings with vruntime
                check_spread()                  just for debug
                        enqueue_entity()
                        put_prev_entity()
                check_preempt_tick()
                        entity_tick()
                migrate_task_rq_smart()         OK
                wakeup_preempt_entity()         OK
                        pick_next_entity()      TODO next, skip, last buddies
                        check_preempt_wakeup()
                vruntime_normalized()           OK
                        detach_task_cfs_rq()
                        attach_task_cfs_rq()
                max_vruntime()                  OK
                        update_min_vruntime()
                        place_entity()
                min_vruntime()                  OK
                        update_min_vruntime()
                        place_entity()
                update_min_vruntime()           OK
                        update_curr()
                        dequeue_entity()

        . calc_delta_fair()                     OK useless
                calculate the virtual delta time regarding the weight of the
                entity
        . check_preempt_tick()                  OK
                Check if the process should be preempted if it has finished its
                timeslice

                TODO: need if scheduler_tick != timeslice

        . Timeslice                             OK
                no fixed timeslice-> calculated at runtime
                between sysctl_sched_min_granularity and sysctl_sched_latency
                                        750,000ns             6,000,000ns

                __sched_period()
                        determine a period in which each task runs once.
                                if nr > 8
                                        nr * 750,000ns
                                else
                                        6,000,000ns

                . sched_slice()
                        based on the period to run each process return by
                        __sched_period(), split the time among the task
                        regarding their load

                        sched_vslice()          OK
                        check_preempt_tick()    OK
                        hrtick_start_fair()
                        get_rr_interval_fair()

                . sched_vslice()                        OK
                        return the virtual timeslice of the entity
                        place_entity()

        . tick == CONFIG_HZ
                - the tick to update the process is CONFIG_HZ (250 or 1000) or
                is determine with high resolution timer with CONFIG_SCHED_HRTICK

                In scheduler_tick, rescheduling is activated with check_preempt_tick()
                which control is the entity has finished is timeslice.

        . debug
                https://lwn.net/Articles/365835/
                https://elinux.org/Kernel_Debugging_Tips
                https://www.slideshare.net/vh21/linux-kernel-tracing
                https://opensourceforu.com/2011/04/kernel-debugging-using-kprobe-and-jprobe/
                http://devarea.com/linux-kernel-development-creating-a-proc-file-and-interfacing-with-user-space/

                dmesg -n 5       -> set log level loglevel < 5
                dmesg -wH        -> follow file evolution
                tail -f filename -> follow file evolution
                watch cat ...

                printk()       -> dmesg -wH
                trace_printk() -> trace in a tracer file

                kprob:
                        kp.pre_handler = pre handler function
                        kp.post_handler = post handler function
                        kp.addr = function to debug
                        register_kprobe();
                        unregister_kprobe(&kp);

                        NOTE: Still use printk

                jprob:
                        like kprob but the handler get the same argument than
                        the function to debug to get the entry arguments

                        jp.kp.addr = function to debug
                        jp.entry = handler
                        jprobe_return(); when returning from handler
                        register_jprobe(&my_probe);
                        unregister_jprobe(&my_probe);

                Create Proc file:

                        struct file_operations
                                .read
                                .write
                                .open
                        proc_create()
                        proc_remove()

                        rewrite sched/debug.c with a new proc for the AI

                create new debug file ???
                create a new trace    ???

        . synchronization_point and batch                       OK
                weight are global


                QUESTION: is timer_list per-CPU? Yes
                        https://lwn.net/Articles/22911/
                        dynamic timer is bound to the CPU that activated it
                QUESTION: is timer_list in interrupt context? Yes
                QUESTION: is it possible to lock with timer_list? Yes
                        read_lock_irq write_lock_irq
                        DEFINE_RWLOCK(x)

                QUESTION: batch methodes?
                        average dw over each update fpor each CPU the batch

        . Set kconfig:                                  OK
                -> /init/Kconfig
                -> kernel/sched/Kconfig
                https://www.kernel.org/doc/Documentation/kbuild/kconfig-language.txt
                CONFIG_SCHED_SFS                n
                CONFIG_SCHED_SFS_TIMESLICE      1000000ns
                CONFIG_SCHED_SFS_SYNCH_TIMER    1000ms
                CONFIG_SCHED_SFS_FIXP_SHIFT     10
                CONFIG_SCHED_SFS_ALPHA          0
                CONFIG_SCHED_SFS_GAMMA          0
                CONFIG_SCHED_SFS_W_LOAD         0
                CONFIG_SCHED_SFS_W_AGV_BLOCK    0
                CONFIG_SCHED_SFS_W_AGV_SLEEP    0
                CONFIG_SCHED_SFS_W_AGV_LOCK     0

                NOTE: the constant should already be scaled to the fixedpoint

        . entity_before() important to avoid any overflow       OK

                - caller:
                        __enqueue_entity
                        pick_next_entity
                        task_fork_fair

                - update min_state in update_aistats()

                        QUESTION: always minimum state in rq or current? no
                                /!\ if state overflow

                        remove_aistats  -> process in rq
                        add_aistate     -> process not in rq
                        update_ai_stats -> curr normaly not in rq

                - when calculating, sub by min_state for all entity state:
                        remove_aistats
                                r -> problem because diff
                                     but no need to subtract min_state
                        add_aistats
                                r -> problem because diff
                                     but no need to subtract min_state
                        update_rewards
                                r_old, r -> problem because diff
                                            but no need to subtract min_state
                        update_next
                                s, s2, si, si2 -> problem is state overflow
                                                  and entity state not

                To reduce the overhead of the calculation, reduce the overflow
                when detected during the update of the runqueue state.

                This required to have min always the real-min state

        . Convergence                           OK
        . Determine default weight              OK

                -> always load weight at the begining, only use it to keep
                -> fair regarding the different process
                -> other == 0

                CONFIG_SCHED_SFS_SYNCH_TIMER    1000
                CONFIG_SCHED_SFS_FIXP_SHIFT     10
                CONFIG_SCHED_SFS_ALPHA          -> 0.5     512
                CONFIG_SCHED_SFS_GAMMA          -> 0.8     820
                CONFIG_SCHED_SFS_W_LOAD         1
                CONFIG_SCHED_SFS_W_AGV_BLOCK    0
                CONFIG_SCHED_SFS_W_AGV_SLEEP    0
                CONFIG_SCHED_SFS_W_AGV_LOCK     0

        . migration task
        https://www.systutorials.com/239971/migration-thread-works-inside-linux-kernel/

                Task is called when stopping and migrating a task to another CPU.
                Thereis one process per cpu.

                The task is initialized during the early_initcall by calling the function
                sched_set_stop_task().

        . RSDTtXZPI                                     fs/proc/array.c
                "R (running)",		/* 0x00 */
        	"S (sleeping)",		/* 0x01 */    TASK_INTERRUPTIBLE
        	"D (disk sleep)",	/* 0x02 */    TASK_UNINTERRUPTIBLE
        	"T (stopped)",		/* 0x04 */
        	"t (tracing stop)",	/* 0x08 */
        	"X (dead)",		/* 0x10 */
        	"Z (zombie)",		/* 0x20 */
        	"P (parked)",		/* 0x40 */
                "I (idle)",		/* 0x80 */

        . set_last_buddy        -> when preempted
        . set_next_buddy        -> when preempted
        . set_skip_buddy        -> when yield

        . QUESTION: When is a task in idle state ???
                 TASK_IDLE -> I
                        set_current_state(TASK_IDLE)
                        __set_current_state(TASK_IDLE)
                        prepare_to_wait(... TASK_IDLE)
                        ___swait_event(... TASK_ILDE ...)
                        ___wait_event(... TASK_ILDE ...)

        . QUESTION: When is a task in sleep state other than blocked ???

                TASK_UNINTERRUPTIBLE -> D

                        prepare_to_wait_exclusive()                     wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        prepare_to_wait()                               wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        prepare_to_wait_event()                         wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        wait_on_bit
                        wait_on_bit_timeout
                        wait_on_bit_lock_io
                                ...
                                        prepare_to_wait_exclusive()
                                        __add_wait_queue_entry_tail()

                        ___swait_event
                                prepare_to_swait_event
                                        prepare_to_swait
                                                __prepare_to_swait
                                                        list_add

                        ___wait_var_event
                        ___wait_event
                                prepare_to_wait_event()
                                        __add_wait_queue_entry_tail()
                                        __add_wait_queue()
                                set_current_state()


                        wait_for_common()                               completion.c
                        wait_for_common_io()
                        wait_for_completion
                        wait_for_completion_timeout
                                __wait_for_common()
                                        do_wait_for_common()
                                                __add_wait_queue_entry_tail_exclusive()
                                        __set_current_state(state);

                        wait_woken                                      wait.c
                                set_current_state()
                                schedule_timeout()

                TASK_INTERRUPTIBLE -> S
                        prepare_to_swait
                        prepare_to_wait_exclusive
                        prepare_to_wait
                        set_current_state
                        __set_current_state
                        wait_woken
                        wait_on_bit

                schedule_timeout()
                __add_wait_queue                                wait.h
                __add_wait_queue_exclusive                      wait.h
                __add_wait_queue_entry_tail                     wait.h
                __add_wait_queue_entry_tail_exclusive           wait.h

                If task always waiting, the execution avg. time will be reduce and
                will influence the decision, no necessarily needed to add sleep and wait.

                =========================================================================
                TODO:
                . Save a specific load with the right shift in the aistats
                . rename dq_value and update
                . use the prev load, sleep avg, block avg, lock avg


https://idea.popcount.org/2012-12-11-linux-process-states/
https://elixir.bootlin.com/linux/v4.17.2/source/include/linux/sched.h#L92
Debugging:

        - rescale, Q, dQ, State, Rewards

  	printk("Debug=========================================================\n");
  	printk("Process: %s\n", p->comm);
  	printk("Debug=========================================================\n");

        #include <linux/sched/ai.h>

        #ifdef CONFIG_SCHED_SFS
        	ai_inc(current->se.aistats.sleep_count);
        #endif

Scaled or not scaled, That is the question:

        aistats:
        --------
        u64 scheduled_count     -> not

        u64 state               -> reduced
        u64 old_state;          -> reduced

        u64 avg_runtime;        -> reduced
        u64 runtime_sum;        -> reduced

        u64 avg_block;          -> scaled
        u64 block_count;        -> not

        u64 avg_sleep;          -> scaled
        u64 sleep_count;        -> not

        u64 avg_lock;           -> scaled
        u64 lock_count;         -> not

        u64 di;                 -> NOT USED !!!
        s64 ut;                 -> scaled
        s64 targ;               -> scaled
        s64 q_value;            -> scaled

        ai:
        ---
        s64 dw_load;            -> scaled
        s64 dw_avg_block;       -> scaled
        s64 dw_avg_sleep;       -> scaled
        s64 dw_avg_lock;        -> scaled
        u64 batch_cnt;

        u64 state;              -> reduced
        u64 min_state;          -> reduced

        s64 q_value;            -> scaled
        s64 dq_value;           -> scaled
        s64 old_q_value;        -> scaled

        s64 ut_sum;             -> scaled

        s64 rewards;            -> scaled and reduced

        update_rewards():
        -----------------
        s64 dij                 -> not
        s64 dij2                -> not
        s64 rewards;            -> not
        u64 min_state;          -> not

        update_next():
        --------------
        s64 s                   -> scaled       based on ai->state
        s64 s2                  -> scaled       based on ai->state + avg_runtime
        s64 si                  -> scaled       based on aistats->state
        s64 si2                 -> scaled       based on aistats->state + avg_runtime
        s64 fi_s                -> scaled       based on targ, s and si
        s64 fi_s2               -> scaled       based on targ, s2 and si2

        update_dq(): -> same than for update_next()
        ------------
        s64 s                   -> scaled
        s64 s2                  -> scaled
        s64 si                  -> scaled
        s64 si2;                -> scaled
        s64 fi_s                -> scaled
        s64 fi_s2;              -> scaled

        update_weights():
        -----------------
        s64 update              -> scaled       based on alpha dq_value rewards
                                                         old_q_value gamma
                                                         q_value

        synch_point():
        --------------
        dw_load                 -> scaled
        dw_avg_block            -> scaled
        dw_avg_sleep            -> scaled
        dw_avg_lock             -> scaled
        cpu_cnt                 -> not


================================================================================
================================================================================
================================================================================
================================================================================
https://www.systutorials.com/240717/load-balancing-work-internal-operating-systems/

TRIGGER BALANCE:
================
scheduler_tick()                                                core.c
        trigger_load_balance()                                  fair.c
                if (time_after_eq(jiffies, rq->next_balance))
                        raise_softirq(SCHED_SOFTIRQ)            softirq.c

SCHEDULE NEXT BALANCE: TODO
======================
update_next_balance()
        get_sd_balance_interval(sd, 0)

CALLBACK:
=========
init_sched_fair_class()                                         fair.c
        open_softirq(SCHED_SOFTIRQ, run_rebalance_domains)      softirq.c

NOTE: The callback function of SCHED_SOFTIRQ is run_rebalance_domains()

REBALANCE:
==========
run_rebalance_domains()                                         fair.c
        update_blocked_averages()
                update_cfs_rq_load_avg()        IF CONFIG_FAIR_GROUP_SCHED
                for_each_leaf_cfs_rq_safe()     ELSE
                        update_load_avg()
        rebalance_domains()
                for_each_domain(cpu, sd)
                        load_balance()
                        sd->last_balance = jiffies
                        interval = sd->balance_interval
                        next_balance = sd->last_balance + interval

LOAD_BALANCE:
=============
load_balance()                                                  fair.c
        should_we_balance()
        find_the_busiest_group()
        find_the_busiest_queue()
        number to try to move: min(sysctl_sched_nr_migrate, nr_running)
        detach_tasks()
                while cfs_tasks not empty
                        list_last_entry(cfs_tasks)       QUESTION: Where deleted from cfs_task
                        can_migrate_task()
                        detach_task()
                                deactivate_task()
                                        ...
                                        dequeue_entity()
                                                account_entity_dequeue()
                                                        list_del_init(&se->group_node)
                                set_task_cpu(p, env->dst_cpu);
                        list_last_entry(env->tasks)
        attach_tasks()
                while env->tasks not empty
                        list_last_entry(env->tasks)
                        list_del_init()
                        attach_task()
                                activate_task()
                                        ...
                                        enqueue_entity()
                                                account_entity_enqueue()
                                                        list_add(&se->group_node, &rq->cfs_tasks)

NOTE: sysctl_sched_nr_migrate = 32

UPDATE LOAD AVG SE:
===================
 update_load_avg()                                                     faire.c
        __update_load_avg_se()
                ___update_load_sum()
                ___update_load_avg()
        update_cfs_rq_load_avg()
                __update_load_avg_cfs_rq()
                        ___update_load_sum()
                        ___update_load_avg()
        propagate_entity_load_avg()
        update_tg_load_avg()

NOTE: tg -> Task group
NOTE: Called by enqueue_entity
                dequeue_entity
                dequeue_task_fair
                enqueue_task_fair
                put_prev_entity
                set_next_entity
                entity_tick
                attach_entity_cfs_rq
                detach_entity_cfs_rq
                sched_group_set_shares
                propagate_entity_cfs_rq
                update_blocked_averages

FIND_BUSIEST_GROUP: TODO: Select which of those condition should be kept
===================
find_busiest_group()                                                    fair.c
        update_sd_lb_stats()
                do {
                        sg = sg->next;
                } while (sg != env->sd->groups);

        check_asym_packing()

        no balance if no busiest or busiest nr_running == 0     -> out balance  KEEP
        calculate domain avg load scaled to capacity
        check if group considered to be imbalanced              -> force balance
        if this cpu is ilde and busiest no capacity             -> force balance
        no balance if this cpu more load that busiest found     -> out balance
        no balance if this cpu above domain average weight      -> balance
        if this cpu idle
                if no imbalance                                 -> out balanced

        force_balance
                calculate_imbalance()
                return busiest
        out_balance
                env_imbalance = 0


FIND_BUSIEST_QUEUE:
===================
find_busiest_queue()                                                    fair.c
        for_each_cpu_and()
                get cpu rq
                get classify (all, regular, remote)
                get capactiy = cpu->cpu_capacity
                weighted_cpuload()
                        cfs_rq_runnable_load_avg()
                                cfs_rq->avg.runnable_load_avg
                select it if:
                        nr_running > 1
                        wl > env->imbalance
                        check_cpu_capacity()

                compare with previous busiest found, keep the best

KTHREAD CREATE:
===============
kthread_create
        kthread_create_on_node
               __kthread_create_on_node

smpboot_register_percpu_thread_cpumask
        __smpboot_create_thread
                 kthread_create_on_cpu
                         kthread_create_on_node
                                __kthread_create_on_node



QUESTION: env->imbalance, calculate_imbalance, It is use somewhere else than find_busiest_queue
QUESTION: sd->imbalance_pct
QUESTION: Relation group, runqueue

NOTE: group_type = group_classify()
NOTE: sd = sched domain, tg = task group, ld = load balance
NOTE: cpu_capacity = SCHED_CAPACITY_SCALE = (1L << SCHED_CAPACITY_SHIFT)
NOTE: SCHED_CAPACITY_SHIFT = SCHED_FIXEDPOINT_SHIFT
NOTE: update_cpu_capacity() -> cpu_rq(cpu)->cpu_capacity

        . Attributes (rename weight for load balance):                           TODO
                Per Entity:
                - avg runtime                                   OK
                - nbr of time scheduled, avg                    avg_sched, interval_cnt->jiffies
                - nbr blocked                                   OK
                - avg time of completion without blocking       avg_comp, comp_count
                - IPC                                           if possible
                - Cache miss                                    if possible

                Per Runqueue:
                - avg runtime                                   sum     avg_runtime_sum
                - nbr of time scheduled, avg                    sum     avg_sched_sum
                - nbr blocked                                   sum     avg_block_sum
                - avg time of completion without blocking       sum     avg_comp_sum

                ----
                u64 prev_avg_runtime    -> per task     scaled     ok
                u64 prev_avg_sched      -> per task     scaled     ok
                u64 prev_avg_block      -> per task     scaled     ok
                u64 prev_avg_comp       -> per task     scaled     ok

                u64 avg_runtime_sb      -> per task     scaled     ok
                u64 avg_sched           -> per task     scaled     ok
                u64 avg_block           -> per task     scaled     ok
                u64 avg_comp            -> per task     scaled     ok

                u64 last_interval       -> per task     not        ok
                u64 interval_count      -> per task     not        ok
                u64 comp_count          -> per task     not        ok
                u64 prev_block_count    -> per task     not        ok

                u64 avg_runtime_sum     -> per task     scaled     ok
                u64 avg_sched_sum       -> per task     scaled     ok
                u64 avg_block_sum       -> per task     scaled     ok
                u64 avg_comp_sum        -> per task     scaled     ok

                s64 balance             -> per task     scaled     ok
                                        -> per queue    scaled     ok

                s64 sb_dw_avg_runtime   -> per queue    scaled     ok
                s64 sb_dw_avg_sched     -> per queue    scaled     ok
                s64 sb_dw_avg_block     -> per queue    scaled     ok
                s64 sb_dw_avg_comp      -> per queue    scaled     ok

                u64 sb_batch_cnt        -> per queue    not        ok

                s64 sb_q_value          -> per task     scaled     ok
                s64 sb_old_q_value      -> per task     scaled     ok

                bool sb_learning        -> per queue    not        ok
                bool sb_dirty_weight    -> per queue    not        ok
                bool moved              -> per task     not        ok

                s64 sb_rewards          -> per task     scaled     ok

                s64 sb_w_avg_sched      -> global       scaled     ok
                s64 sb_w_avg_runtime    -> global       scaled     ok
                s64 sb_w_avg_block      -> global       scaled     ok
                s64 sb_w_avg_comp       -> global       scaled     ok

                u64 sb_conv_limit       -> global       not        ok
                u64 sb_conv_runtime     -> global       not        ok
                u64 sb_conv_sched       -> global       not        ok
                u64 sb_conv_block       -> global       not        ok
                u64 sb_conv_comp        -> global       not        ok

                s64 sb_alpha            -> global       scaled     ok
                s64 sb_gamma            -> global       scaled     ok
                ----

                The attributes are updated by:
                . update_curr()                                                 ok
                . enqueue_entity()                                              ok
                . dequeue_entity()                                              ok
                . init_aistats()                                                OK
                . init_ai()                                                     OK
                . detach_task_cfs_rq                                            ok
                . attach_task_cfs_rq                                            ok


        . load_balance()                                                        ok
                - Considering state of queue and entity up to date

                1. select queue with the worst state TODO: Group, queue
                        - group -> sum state of queue
                2. Calculate Q(s,a) for each entity and decide to move or not
                3. calculate dQ
                4. Update with rewards at the next load balance
                5. rewards:
                        - save info in entity
                        - raised a flag moved in the entity
                        - at next balanced in the new cpu
                                . calculate the rewards
                                . update dw
                                . reset moved flag

                NOTE: Using batch make no different if weight updated on new
                      CPU or old one.

                      rq->cfs_task

                QUESTION: How to determine process that called load balance ??
                        -> trigger_load_balance() is run periodically on each CPU
                        through scheduler_tick()

        . update_balance_rewards                                                OK
        . update_balance_group                                                  OK
        . update_balance_weight                                                 OK
        . detach_tasks()                                                        OK
                . when balance <= 0 what to do ?
                        -> balance = q_value -> nothing to do. stop only if
                           no more task
                . consider affinity -> can't move the task                      OK
        . attach_tasks()                                                        OK
                -> no modification

        . Snychronization for balance                                           OK
                -> dirty weight
        . init task                                                             ok
        . init queue                                                            ok
        . debug                                                                 ok
        . Makefile                                                              ok
        . scale Q                                                               ok
        . move state used from enqueu/dequeu_entity to __enqueue/dequeue_entity ok
                and removed from detach/attach_task_cfs_rq
        . Signed-unsigned                                                       TODO
        . Check scale of local variable                                         TODO
        . balance interval                                                      TODO
        . Default weight: SB (Smart Balance)                                    TODO

                -> dependent of CONFIG_SCHED_SFS
                CONFIG_SCHED_SB                 1
                CONFIG_SCHED_SB_SYNCH_TIMER     10000           -> 10s
                CONFIG_SCHED_SB_FIXP_SHIFT      use SFS
                CONFIG_SCHED_SB_CONV            1024
                CONFIG_SCHED_SB_ALPHA           512
                CONFIG_SCHED_SB_GAMMA           820

                CONFIG_SCHED_SB_W_AVG_RUN       -1024
                CONFIG_SCHED_SB_W_AVG_BLOCK     -1024
                CONFIG_SCHED_SB_W_AVG_SCHED     -1024
                CONFIG_SCHED_SB_W_AVG_COMP      -1024

                CONFIG_SCHED_SB_INTERVAL        1000

        . remove useless stuff

Debug:
        . comp and sched -> use a global interval per cfs not entity
                - comp -> on interval but update in pick_next_entity -> other update plenty of time
                - sched -> use interval regarding rq
        . balance positive
                /!\, detach/attach_task update the average in enqueue/dequeue_entity
                BUT it is already done in detach_task
        . sum not equal to the actual value -> because task sleeping and previous udpate use them
        . problem: e.g init -> if sleeping, attribute should no more be used
        . update to big -> reduct attributes, scale sum and average             TODO
        . average: value of src wrong, queue always bigger than debug           OK
                -> busiest queue unlock between attach and detach
        . state correct -> nope                                                 TODO
                - same entity? ksoftirqd/1 cpuhp/1
                - same problem than for migration task
                        cpuhp/1 ksoftirqd/1 kworker/1:0 kworker/1:0H rcu_sched

                        kthread_create -> TODO BUt still not this

                update_aistats          KO
                enqueue_entity          OK
                dequeue_entity          OK
                migrate_task_rq_smart   OK
                task_fork_smart         OK

                update_aistats + migrate_task_rq_smart  KO ???????
                update_aistats + dequeue_entity         KO ??? -> state_used=false misplaced

                /!\ IF IN UPDATE_CURR()

                migrate_task_rq_smart -> consider min_state = min(min_state, se->aistats.state);

Useless
        should_we_balance
        find_busiest_group
        find_busiest_queue

????
        fbd_classify_rq
        get_sd_load_idx
        SD_PREFER_SIBLING
        task_h_load
        sched_feat


        balance value with learning
REDUCT_BALANCE




        warning: TCG doesn't support requested feature: CPUID.01H:ECX.vmx [bit 5]
        warning: TCG doesn't support requested feature: CPUID.01H:ECX.vmx [bit 5]
        [    0.000000] Linux version 4.17.2 (nathan@nathan) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10)) #514 SMP Mon Jul 23 08:58:07 BST 2018
        [    0.000000] Command line: console=ttyS0
        [    0.000000] x86/fpu: x87 FPU will use FXSAVE
        [    0.000000] e820: BIOS-provided physical RAM map:
        [    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable
        [    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved
        [    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved
        [    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000001ffdffff] usable
        [    0.000000] BIOS-e820: [mem 0x000000001ffe0000-0x000000001fffffff] reserved
        [    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved
        [    0.000000] NX (Execute Disable) protection: active
        [    0.000000] SMBIOS 2.8 present.
        [    0.000000] DMI: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
        [    0.000000] e820: last_pfn = 0x1ffe0 max_arch_pfn = 0x400000000
        [    0.000000] x86/PAT: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT
        [    0.000000] found SMP MP-table at [mem 0x000f6620-0x000f662f] mapped at [        (ptrval)]
        [    0.000000] Scanning 1 areas for low memory corruption
        [    0.000000] RAMDISK: [mem 0x1cd7d000-0x1ffdffff]
        [    0.000000] ACPI: Early table checksum verification disabled
        [    0.000000] ACPI: RSDP 0x00000000000F63F0 000014 (v00 BOCHS )
        [    0.000000] ACPI: RSDT 0x000000001FFE1737 000034 (v01 BOCHS  BXPCRSDT 00000001 BXPC 00000001)
        [    0.000000] ACPI: FACP 0x000000001FFE0C14 000074 (v01 BOCHS  BXPCFACP 00000001 BXPC 00000001)
        [    0.000000] ACPI: DSDT 0x000000001FFE0040 000BD4 (v01 BOCHS  BXPCDSDT 00000001 BXPC 00000001)
        [    0.000000] ACPI: FACS 0x000000001FFE0000 000040
        [    0.000000] ACPI: SSDT 0x000000001FFE0C88 0009F7 (v01 BOCHS  BXPCSSDT 00000001 BXPC 00000001)
        [    0.000000] ACPI: APIC 0x000000001FFE167F 000080 (v01 BOCHS  BXPCAPIC 00000001 BXPC 00000001)
        [    0.000000] ACPI: HPET 0x000000001FFE16FF 000038 (v01 BOCHS  BXPCHPET 00000001 BXPC 00000001)
        [    0.000000] No NUMA configuration found
        [    0.000000] Faking a node at [mem 0x0000000000000000-0x000000001ffdffff]
        [    0.000000] NODE_DATA(0) allocated [mem 0x1cd79000-0x1cd7cfff]
        [    0.000000] tsc: Fast TSC calibration using PIT
        [    0.000000] Zone ranges:
        [    0.000000]   DMA      [mem 0x0000000000001000-0x0000000000ffffff]
        [    0.000000]   DMA32    [mem 0x0000000001000000-0x000000001ffdffff]
        [    0.000000]   Normal   empty
        [    0.000000] Movable zone start for each node
        [    0.000000] Early memory node ranges
        [    0.000000]   node   0: [mem 0x0000000000001000-0x000000000009efff]
        [    0.000000]   node   0: [mem 0x0000000000100000-0x000000001ffdffff]
        [    0.000000] Initmem setup node 0 [mem 0x0000000000001000-0x000000001ffdffff]
        [    0.000000] Reserved but unavailable: 98 pages
        [    0.000000] ACPI: PM-Timer IO Port: 0x608
        [    0.000000] ACPI: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])
        [    0.000000] IOAPIC[0]: apic_id 0, version 17, address 0xfec00000, GSI 0-23
        [    0.000000] ACPI: INT_SRC_OVR (bus 0 bus_irq 0 global_irq 2 dfl dfl)
        [    0.000000] ACPI: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)
        [    0.000000] ACPI: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)
        [    0.000000] ACPI: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)
        [    0.000000] ACPI: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)
        [    0.000000] Using ACPI (MADT) for SMP configuration information
        [    0.000000] ACPI: HPET id: 0x8086a201 base: 0xfed00000
        [    0.000000] smpboot: Allowing 2 CPUs, 0 hotplug CPUs
        [    0.000000] PM: Registered nosave memory: [mem 0x00000000-0x00000fff]
        [    0.000000] PM: Registered nosave memory: [mem 0x0009f000-0x0009ffff]
        [    0.000000] PM: Registered nosave memory: [mem 0x000a0000-0x000effff]
        [    0.000000] PM: Registered nosave memory: [mem 0x000f0000-0x000fffff]
        [    0.000000] e820: [mem 0x20000000-0xfffbffff] available for PCI devices
        [    0.000000] clocksource: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns
        [    0.000000] random: get_random_bytes called from start_kernel+0x8b/0x4c7 with crng_init=0
        [    0.000000] setup_percpu: NR_CPUS:64 nr_cpumask_bits:64 nr_cpu_ids:2 nr_node_ids:1
        [    0.000000] percpu: Embedded 43 pages/cpu @        (ptrval) s137496 r8192 d30440 u1048576
        [    0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 128873
        [    0.000000] Policy zone: DMA32
        [    0.000000] Kernel command line: console=ttyS0
        [    0.000000] Memory: 437808K/523768K available (12300K kernel code, 1294K rwdata, 3104K rodata, 1232K init, 620K bss, 85960K reserved, 0K cma-reserved)
        [    0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=2, Nodes=1
        [    0.000000] Hierarchical RCU implementation.
        [    0.000000] 	RCU event tracing is enabled.
        [    0.000000] 	RCU restricting CPUs from NR_CPUS=64 to nr_cpu_ids=2.
        [    0.000000] RCU: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=2
        [    0.000000] NR_IRQS: 4352, nr_irqs: 440, preallocated irqs: 16
        [    0.000000] Console: colour VGA+ 80x25
        [    0.000000] console [ttyS0] enabled
        [    0.000000] ACPI: Core revision 20180313
        [    0.000000] clocksource: hpet: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 19112604467 ns
        [    0.000000] APIC: Switch to symmetric I/O mode setup
        [    0.007000] ..TIMER: vector=0x30 apic1=0 pin1=2 apic2=-1 pin2=-1
        [    0.012000] tsc: Fast TSC calibration using PIT
        [    0.013000] tsc: Detected 2394.509 MHz processor
        [    0.015124] tsc: Marking TSC unstable due to TSCs unsynchronized
        [    0.015487] Calibrating delay loop (skipped), value calculated using timer frequency.. 4789.01 BogoMIPS (lpj=2394509)
        [    0.016097] pid_max: default: 32768 minimum: 301
        [    0.017045] Security Framework initialized
        [    0.017344] SELinux:  Initializing.
        [    0.019168] Dentry cache hash table entries: 65536 (order: 7, 524288 bytes)
        [    0.019735] Inode-cache hash table entries: 32768 (order: 6, 262144 bytes)
        [    0.020184] Mount-cache hash table entries: 1024 (order: 1, 8192 bytes)
        [    0.020454] Mountpoint-cache hash table entries: 1024 (order: 1, 8192 bytes)
        [    0.034716] mce: CPU supports 10 MCE banks
        [    0.035942] Last level iTLB entries: 4KB 0, 2MB 0, 4MB 0
        [    0.036262] Last level dTLB entries: 4KB 0, 2MB 0, 4MB 0, 1GB 0
        [    0.036582] Spectre V2 : Spectre mitigation: LFENCE not serializing, switching to generic retpoline
        [    0.037000] Spectre V2 : Mitigation: Full generic retpoline
        [    0.037284] Spectre V2 : Spectre v2 mitigation: Filling RSB on context switch
        [    0.037623] Speculative Store Bypass: Vulnerable
        [    0.041258] Freeing SMP alternatives memory: 36K
        [    0.057000] smpboot: CPU0: AMD QEMU Virtual CPU version 2.5+ (family: 0x6, model: 0x6, stepping: 0x3)
        [    0.062281] Performance Events: PMU not available due to virtualization, using software events only.
        [    0.065351] Hierarchical SRCU implementation.
        [    0.070506] Huh? What family is it: 0x6?!
        [    0.072572] smp: Bringing up secondary CPUs ...
        [    0.075697] x86: Booting SMP configuration:
        [    0.076050] .... node  #0, CPUs:      #1
        [    0.155564] smp: Brought up 1 node, 2 CPUs
        [    0.156072] smpboot: Max logical packages: 2
        [    0.156325] smpboot: Total of 2 processors activated (14859.34 BogoMIPS)
        [    0.165500] BUG: unable to handle kernel NULL pointer dereference at 0000000000000288
        [    0.165500] PGD 0 P4D 0
        [    0.165500] Oops: 0000 [#1] SMP NOPTI
        [    0.165500] Modules linked in:
        [    0.165500] CPU: 1 PID: 15 Comm: ksoftirqd/1 Not tainted 4.17.2 #514
        [    0.165500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
        [    0.165500] RIP: 0010:pick_next_task_smart+0x472/0x6a0
        [    0.165500] RSP: 0018:ffffa6b50014be20 EFLAGS: 00000086
        [    0.165500] RAX: 0000000000000000 RBX: ffff89929cb20740 RCX: 0000000000000000
        [    0.165500] RDX: ffff89929cb208c0 RSI: 0000000000000000 RDI: ffff89929cb207c0
        [    0.165500] RBP: ffff89929cb207c0 R08: 0000000000000000 R09: ffff89929cb208c0
        [    0.165500] R10: 0000000000000000 R11: 0000000000000000 R12: ffff89929b9bd100
        [    0.165500] R13: ffffa6b50014be90 R14: 0000000000000000 R15: ffff89929cb20740
        [    0.165500] FS:  0000000000000000(0000) GS:ffff89929cb00000(0000) knlGS:0000000000000000
        [    0.165500] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
        [    0.165500] CR2: 0000000000000288 CR3: 0000000010a0a000 CR4: 00000000000006e0
        [    0.165500] Call Trace:
        [    0.165500]  __schedule+0x100/0x820
        [    0.165500]  schedule+0x2d/0x80
        [    0.165500]  smpboot_thread_fn+0xbc/0x160
        [    0.165500]  kthread+0xf3/0x130
        [    0.165500]  ? sort_range+0x20/0x20
        [    0.165500]  ? kthread_destroy_worker+0x40/0x40
        [    0.165500]  ret_from_fork+0x35/0x40
        [    0.165500] Code: 93 a0 00 00 00 49 89 87 a0 0a 00 00 66 66 66 66 90 48 83 83 c0 01 00 00 01 48 89 d8 e9 25 fd ff ff 31 f6 48 89 ef e8 8e 7c ff ff <48> 8b a8 88 02 00 00 48 85 ed 0f 84 b5 00 00 00 48 8b b5 10 01
        [    0.165500] RIP: pick_next_task_smart+0x472/0x6a0 RSP: ffffa6b50014be20
        [    0.165500] CR2: 0000000000000288
        [    0.165500] ---[ end trace f0155efabb822db8 ]---
        QEMU: Terminated
