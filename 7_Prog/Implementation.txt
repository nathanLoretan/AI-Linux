TIMESLICE
=========
sched_slice()                                           smart.c
        __sched_period()                                smart.c

Modified, return a constant timeslice CONFIG_SCHED_SFS_TIMESLICE no more
          __sched_period()

RQ INIT
=======

sched_init()                                            core.c
        for_each_possible_cpu() ->
                init_cfs_rq()                           smart.c
        init_synch_point()

Modified, Initialize the different factors and weights used by the AI and
          initialize the list that store the entity

CREATE NEW PROCESS
==================

kernel_thread()                                         fork.c
  do_fork()

do_fork()                                               fork.c
  _do_fork()
          copy_process()
                          dup_task_struct()       -> create the task
                          sched_fork()            core.c
          wake_up_new_task()                      core.c
                  activate_task()                 core.c

sched_fork()                                      core.c -> set rq of se
        __sched_fork()                            -> set sched_entity
        __set_task_cpu()
                set_task_rq()
        task_fork_smart()                         smart.c
                init_aistats()
                if curr -> update_curr
                place_entity()                    TODO
                normalize state

Modified, initialize the aistats structure of the new state, give the state
          of the parent process and normalize the state

ADD TASK IN QUEUE
=================

activate_task()                                                 core.c
        enqueue_task()
                enqueue_task_smart()                            smart.c
                        enqueue_entity()                        -> initialise vruntime of the process
                                if curr -> normalize
                                update_curr()
                                if !curr & !sleep -> normalize
                                if !state_used -> add_aistats()
                                if !curr -> __enqueue_entity()     -> entity not in rq
                                se->on_rq = 1

Modified,

REMOVE TASK QUEUE
=================

deactivate_task()                                               core.c
        dequeue_task()
                dequeue_task_smart()                            smart.c
                        dequeue_entity()
                                update_curr()
                                if !state_used -> remove_aistats()  -> entity still in rq
                                if !curr -> __dequeue_entity()
                                if !sleep -> Normalize state
                                se->on_rq = 0
                        set_next_buddy()

QUESTION: What call deactivate_task() ?

When migrating process:
detach_task()
        deactivate_task()

When scheduling, if !preempt && task not running (TASK_RUNNING = 0) and
                    !signal_pending_state(prev->state, prev)
__schedule()
        deactivate_task()

signal_pending_state(prev->state, prev)
        return 0 if state not (TASK_INTERRUPTIBLE | TASK_WAKEKILL)
        return 0 if TASK_INTERRUPTIBLE and signal not yet received

Modified,

UPDATE CURRENT ENTITY STATE AND RUNQUEUE STATE
==============================================

scheduler_tick()                                                core.c
        task_tick_smart()                                       smart.c
                entity_tick()
                        update_curr()
                                update_aistats()
                                update_state()
                                update_rewards()
                        resched_curr()

hrtick_start_fair()                                             smart.c
        sched_slice()
        hrtick_start() -> start time slice                      core.c

hrtick -> after finishing timeslice                             core.c
        task_tick_smart()                                       smart.c



Modified, update the state of the entity and the runqueue and set schedul
          flag

SELECT NEW PROCESS
==================

resched_curr()  -> set TIF_NEED_RESCHED

schedule()                                                      core.c
        __schedule()
                pick_next_task()
                        pick_next_task_smart()                  smart.c
                                if curr->on_rq -> update_curr()
                                pick_next_entity()
                                        update_weights()
                                        update_next()

                		put_prev_entity()
                                        if still runnable
                                                update_curr()
                                                _enqueue_entity()

                                set_next_entity()
                                        _dequeue_entity()

Modified, Calculate the utility of the next task and select it to run next

/!\ When selecting new process, remove_aistats and add_aistats are not called

SEMAPHORE and READ/WRITE SEM
============================

down()                                                          semaphore.c
        __down()
                __down_common()
                        __set_current_state(TASK_UNINTERRUPTIBLE)
                        list_add_tail(wait_list)
                        block_count++
                        schedule_timeout()                      timer.c
                                schedule()                      core.c
        lock_count++

NOTE: same for down_interruptible() down_killable() down_timeout()
NOTE: not for down_trylock() -> no wait

down_read()                                                     rwsem.c
        __down_read()
                __down_read_common()                            rwsem-spinlock.c
                        block_count++
                        list_add_tail(wait_list)
                        schedule()                              core.c
        lock_count++

NOTE: same for down_read_killable() down_write() down_write_killable()
NOTE: not for down_read_trylock() and down_write_trylock() -> no wait

up()                                                            semaphore.c
        __up()
                list_first_entry(wait_list)
                wake_up_process()                               core.c

up_read()                                                       rwsem.c
        __up_read()                                             rwsem-spinlock.c
                __rwsem_wake_one_writer()
                        list_entry()
                wake_up_process()

up_write()                                                      rwsem.c
        __up_write()                                            rwsem-spinlock.c
                __rwsem_do_wake()
                         list_entry()
                wkae_up_process()

Modified, add lock_count++ and block_count++

MUTEX
=====

NOTE: slowpath == sleep if fast path doesn't work

mutex_lock()                                                    mutex.c
        __mutex_lock_slowpath()
                __mutex_lock()
                        __mutex_lock_common()
                                list_add_tail(waiter.list)
                                block_count++
        lock_count++

NOTE: same for mutex_lock_interruptible() mutex_killable()
NOTE: not for mutex_trylock()

mutex_unlock()                                                    mutex.c
        __mutex_unlock_slowpath()
                list_first_entry()
                wake_up_add()
                wake_up_q()

Modified, add lock_count++ and block_count++

SPIN-LOCK
=========

spin_lock()                                                     spinlock.h
        raw_spin_lock()
                _raw_spin_lock()                                spinlock.c
                        __raw_spin_lock()                       spinlock_api_smp.h
                                do_raw_spin_lock()              spinlock_debug.c

NOTE: same for spin_lock_irqsave() spin_lock_bh() write_lock() read_lock()

spin_unlock()                                                   spinlock.h
        raw_spin_unlock()
                __raw_spin_unlock()                             spinlock_api_smp.h
                        do_raw_spin_unlock()                    spinlock_debug.c

NOTE: same for spin_unlock_irqrestore() spin_unlock_bh() write_unlock() read_unlock()

Modified, None

SLEEP
=====

udelay()        -> busy_wait_loop

usleep_range()                                          timer.c
        sleep_count++
        __set_current_state(TASK_UNINTERRUPTIBLE)
        schedule_hrtimeout_range()                      hrtimer.c
                ...
                        enqueue_hrtimer()
                                timerqueue_add()        timerqueue.c
                schedule()


        remove_hrtimer                                  hrtimer.c
                timerqueue_del                          timerqueue.c

msleep()                                                timer.c
        sleep_count++
        schedule_timeout_uninterruptible()
                __set_current_state(TASK_UNINTERRUPTIBLE)
        	schedule_timeout(timeout)

msleep_interruptible()                                  timer.c
        sleep_count++
        schedule_timeout_interruptible()
                __set_current_state(TASK_INTERRUPTIBLE)
                schedule_timeout(timeout)

schedule_timeout() -> callback function process_timeout
         process_timeout()                              timer.c
                wake_up_process()                       core.c

Modified, add sleep_count++

WAKE UP
=======

wake_up_process()                                               core.c
        try_to_wake_up()
                ttwu_remote() if p->on_rq
                        ttwu_do_wakeup()
                                p->state = TASK_RUNNING

                ttwu_queue()
                        ttwu_do_activate()
                                ttwu_activate()
                                        activate_task()
                                ttwu_do_wakeup()
                                        p->state = TASK_RUNNING

Modified, None

KILL
====

do_exit()                                               exit.c
        set_current_state(TASK_UNINTERRUPTIBLE)
        schedule()
                __schedule()
                        deactivate_task()

do_group_exit()
        do_exit()

Modified, None

YIELD
=====

yield()                                                 core.c
        do_sched_yield()
                yield_task_fair()                       smart.c
                        update_curr()
                        set_skip_buddy()
                schedule()                              core.c

yield_to()                                              core.c
        yield_to_task_fair()                            smart.c
                yield_task_fair()

Modified, None

-------

put_prev_task_fair()                                    smart.c
        put_prev_entity()

set_curr_task_fair()                                    smart.c
        set_next_entity()

Modified, None

-------

static void remove_aistats(struct cfs_rq *cfs_rq, struct sched_entity *old)
static void add_aistats(struct cfs_rq *cfs_rq, struct sched_entity *new)

TODO:   . Initialize AI in runqueue                    -> init_cfs_rq()                OK
        . Initialize sched_entity in new process       -> task_fork_smart()            OK
        . Update environement when deleting a task     -> dequeue_entity()             OK
        . Update environement when adding a task       -> enqueue_entity()             OK
        . Change group                                                                 OK
                -> switched_from() & task_change_group()
                => detach_task_cfs_rq & attach_task_cfs_rq
        . Calculate the utility of the next task       -> pick_next_task_smart()       OK
        . Update the environment                       -> update_curr()                OK
                - creating      OK
                - deleting      OK
                - sleeping      OK
                - blocking      OK
                - scheduling    OK
                - wake-up       OK
        . Set attributes with macro:
                scheduled_count                         -> smart.c      OK
                        pick_next_task_smart()

                runtime_sum                             -> smart.c      OK
                        update_aistats()

                state                                   -> smart.c      OK
                        update_state()
                        enqueue_entity()
                        dequeue_entity()
                        task_fork_smart

                sleep_count                             -> timer.c      OK
                        usleep_range()
                        msleep()
                        msleep_interruptible()
                        yield_task_smart()

                lock_count
                        down()                          -> semaphore.c  OK
                        down_interruptible()
                        down_killable()
                        down_trylock()
                        down_timeout()

                        down_read()                     -> rwsem.c      OK
                        down_read_killable()
                        down_read_trylock()

                        down_write()                    -> rwsem.c      OK
                        down_write_killable()
                        down_write_trylock()

                        mutex_lock()                    -> mutex.c      OK
                        mutex_lock_interruptible()
                        mutex_lock_killable()
                        mutex_trylock()

                block_count, only the added to the wait list            OK
                        __down_common()                 -> semaphore.c
                        __down_read_common()            -> rwsem-spinlock.c
                        __down_write_common()
                        __mutex_lock_common()           -> mutex.c

        . Average, Calcul, Fixed Point, Overflow                        OK

                update_rewards()        OK
                update_aistats()        OK
                update_weights()        OK
                update_next()           OK

                add(a, b, ta, tb) 	 a + b
                sub(a, b, t1, t2)  	 a - b
                mul(a, b, t1, t2)	(a * b) >> Q
                div(a, b, t1, t2)	(a << Q) / b

                Type:
                u32     ->      0 to 4,294,967,295
                s32     ->      -2,147,483,648 to 2,147,483,647
                u64     ->      0 to 18,446,744e12
                s64     ->      -9,223,372e12 to 9,223,372e12

                What to scale:
                x avg_runtime   x alpha         x w_load        x rewards
                x avg_block     x gamma         x w_avg_block   x ut
                x avg_sleep     x q_value       x w_avg_sleep   x ut_sum
                x avg_lock      x old_q_value   x w_avg_lock

                Type definition: all s64
                - alpha                         - scheduled_count
                - gamma                         - state
                - w_load                        - old_state
                - w_avg_block
                - w_avg_sleep                   - avg_runtime
                - w_avg_lock                    - runtime_sum
                - state                         - avg_block
                - q_value                       - block_count
                - old_q_value                   - avg_sleep
                - ut_sum                        - sleep_count
                - update                        - avg_lock
                - rewards                       - lock_count
                - min_start_state               - di
                - min_state                     - ut

                overflow:
                        scheduled_count
                        runtime_sum
                        block_count
                        sleep_count
                        lock_count

        . place_entity()                        OK
        . Remove everythings with vruntime
                check_spread()                  just for debug
                        enqueue_entity()
                        put_prev_entity()
                check_preempt_tick()
                        entity_tick()
                migrate_task_rq_smart()         OK
                wakeup_preempt_entity()         OK
                        pick_next_entity()      TODO next, skip, last buddies
                        check_preempt_wakeup()
                vruntime_normalized()           OK
                        detach_task_cfs_rq()
                        attach_task_cfs_rq()
                max_vruntime()                  OK
                        update_min_vruntime()
                        place_entity()
                min_vruntime()                  OK
                        update_min_vruntime()
                        place_entity()
                update_min_vruntime()           OK
                        update_curr()
                        dequeue_entity()

        . calc_delta_fair()                     OK useless
                calculate the virtual delta time regarding the weight of the
                entity
        . check_preempt_tick()                  OK
                Check if the process should be preempted if it has finished its
                timeslice

                TODO: need if scheduler_tick != timeslice

        . Timeslice                             OK
                no fixed timeslice-> calculated at runtime
                between sysctl_sched_min_granularity and sysctl_sched_latency
                                        750,000ns             6,000,000ns

                __sched_period()
                        determine a period in which each task runs once.
                                if nr > 8
                                        nr * 750,000ns
                                else
                                        6,000,000ns

                . sched_slice()
                        based on the period to run each process return by
                        __sched_period(), split the time among the task
                        regarding their load

                        sched_vslice()          OK
                        check_preempt_tick()    OK
                        hrtick_start_fair()
                        get_rr_interval_fair()

                . sched_vslice()                        OK
                        return the virtual timeslice of the entity
                        place_entity()

        . tick == CONFIG_HZ
                - the tick to update the process is CONFIG_HZ (250 or 1000) or
                is determine with high resolution timer with CONFIG_SCHED_HRTICK

                In scheduler_tick, rescheduling is activated with check_preempt_tick()
                which control is the entity has finished is timeslice.

        . debug
                https://lwn.net/Articles/365835/
                https://elinux.org/Kernel_Debugging_Tips
                https://www.slideshare.net/vh21/linux-kernel-tracing
                https://opensourceforu.com/2011/04/kernel-debugging-using-kprobe-and-jprobe/
                http://devarea.com/linux-kernel-development-creating-a-proc-file-and-interfacing-with-user-space/

                dmesg -n 5       -> set log level loglevel < 5
                dmesg -wH        -> follow file evolution
                tail -f filename -> follow file evolution
                watch cat ...

                printk()       -> dmesg -wH
                trace_printk() -> trace in a tracer file

                kprob:
                        kp.pre_handler = pre handler function
                        kp.post_handler = post handler function
                        kp.addr = function to debug
                        register_kprobe();
                        unregister_kprobe(&kp);

                        NOTE: Still use printk

                jprob:
                        like kprob but the handler get the same argument than
                        the function to debug to get the entry arguments

                        jp.kp.addr = function to debug
                        jp.entry = handler
                        jprobe_return(); when returning from handler
                        register_jprobe(&my_probe);
                        unregister_jprobe(&my_probe);

                Create Proc file:

                        struct file_operations
                                .read
                                .write
                                .open
                        proc_create()
                        proc_remove()

                        rewrite sched/debug.c with a new proc for the AI

                create new debug file ???
                create a new trace    ???

        . synchronization_point and batch                       OK
                weight are global


                QUESTION: is timer_list per-CPU? Yes
                        https://lwn.net/Articles/22911/
                        dynamic timer is bound to the CPU that activated it
                QUESTION: is timer_list in interrupt context? Yes
                QUESTION: is it possible to lock with timer_list? Yes
                        read_lock_irq write_lock_irq
                        DEFINE_RWLOCK(x)

                QUESTION: batch methodes?
                        average dw over each update fpor each CPU the batch

        . Set kconfig:                                  OK
                -> /init/Kconfig
                -> kernel/sched/Kconfig
                https://www.kernel.org/doc/Documentation/kbuild/kconfig-language.txt
                CONFIG_SCHED_SFS                n
                CONFIG_SCHED_SFS_TIMESLICE      1000000ns
                CONFIG_SCHED_SFS_SYNCH_TIMER    1000ms
                CONFIG_SCHED_SFS_FIXP_SHIFT     10
                CONFIG_SCHED_SFS_ALPHA          0
                CONFIG_SCHED_SFS_GAMMA          0
                CONFIG_SCHED_SFS_W_LOAD         0
                CONFIG_SCHED_SFS_W_AGV_BLOCK    0
                CONFIG_SCHED_SFS_W_AGV_SLEEP    0
                CONFIG_SCHED_SFS_W_AGV_LOCK     0

                NOTE: the constant should already be scaled to the fixedpoint

        . entity_before() important to avoid any overflow       OK

                - caller:
                        __enqueue_entity
                        pick_next_entity
                        task_fork_fair

                - update min_state in update_aistats()

                        QUESTION: always minimum state in rq or current? no
                                /!\ if state overflow

                        remove_aistats  -> process in rq
                        add_aistate     -> process not in rq
                        update_ai_stats -> curr normaly not in rq

                - when calculating, sub by min_state for all entity state:
                        remove_aistats
                                r -> problem because diff
                                     but no need to subtract min_state
                        add_aistats
                                r -> problem because diff
                                     but no need to subtract min_state
                        update_rewards
                                r_old, r -> problem because diff
                                            but no need to subtract min_state
                        update_next
                                s, s2, si, si2 -> problem is state overflow
                                                  and entity state not

                To reduce the overhead of the calculation, reduce the overflow
                when detected during the update of the runqueue state.

                This required to have min always the real-min state

        . Convergence                           OK
        . Determine default weight              OK

                -> always load weight at the begining, only use it to keep
                -> fair regarding the different process
                -> other == 0

                CONFIG_SCHED_SFS_SYNCH_TIMER    1000
                CONFIG_SCHED_SFS_FIXP_SHIFT     10
                CONFIG_SCHED_SFS_ALPHA          -> 0.5     512
                CONFIG_SCHED_SFS_GAMMA          -> 0.8     820
                CONFIG_SCHED_SFS_W_LOAD         1
                CONFIG_SCHED_SFS_W_AGV_BLOCK    0
                CONFIG_SCHED_SFS_W_AGV_SLEEP    0
                CONFIG_SCHED_SFS_W_AGV_LOCK     0

        . migration task
        https://www.systutorials.com/239971/migration-thread-works-inside-linux-kernel/

                Task is called when stopping and migrating a task to another CPU.
                Thereis one process per cpu.

                The task is initialized during the early_initcall by calling the function
                sched_set_stop_task().

        . RSDTtXZPI                                     fs/proc/array.c
                "R (running)",		/* 0x00 */
        	"S (sleeping)",		/* 0x01 */    TASK_INTERRUPTIBLE
        	"D (disk sleep)",	/* 0x02 */    TASK_UNINTERRUPTIBLE
        	"T (stopped)",		/* 0x04 */
        	"t (tracing stop)",	/* 0x08 */
        	"X (dead)",		/* 0x10 */
        	"Z (zombie)",		/* 0x20 */
        	"P (parked)",		/* 0x40 */
                "I (idle)",		/* 0x80 */

        . set_last_buddy        -> when preempted
        . set_next_buddy        -> when preempted
        . set_skip_buddy        -> when yield

        . QUESTION: When is a task in idle state ???
                 TASK_IDLE -> I
                        set_current_state(TASK_IDLE)
                        __set_current_state(TASK_IDLE)
                        prepare_to_wait(... TASK_IDLE)
                        ___swait_event(... TASK_ILDE ...)
                        ___wait_event(... TASK_ILDE ...)

        . QUESTION: When is a task in sleep state other than blocked ???

                TASK_UNINTERRUPTIBLE -> D

                        prepare_to_wait_exclusive()                     wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        prepare_to_wait()                               wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        prepare_to_wait_event()                         wait.c
                                __add_wait_queue_entry_tail()
                                set_current_state()

                        wait_on_bit
                        wait_on_bit_timeout
                        wait_on_bit_lock_io
                                ...
                                        prepare_to_wait_exclusive()
                                        __add_wait_queue_entry_tail()

                        ___swait_event
                                prepare_to_swait_event
                                        prepare_to_swait
                                                __prepare_to_swait
                                                        list_add

                        ___wait_var_event
                        ___wait_event
                                prepare_to_wait_event()
                                        __add_wait_queue_entry_tail()
                                        __add_wait_queue()
                                set_current_state()


                        wait_for_common()                               completion.c
                        wait_for_common_io()
                        wait_for_completion
                        wait_for_completion_timeout
                                __wait_for_common()
                                        do_wait_for_common()
                                                __add_wait_queue_entry_tail_exclusive()
                                        __set_current_state(state);

                        wait_woken                                      wait.c
                                set_current_state()
                                schedule_timeout()

                TASK_INTERRUPTIBLE -> S
                        prepare_to_swait
                        prepare_to_wait_exclusive
                        prepare_to_wait
                        set_current_state
                        __set_current_state
                        wait_woken
                        wait_on_bit

                schedule_timeout()
                __add_wait_queue                                wait.h
                __add_wait_queue_exclusive                      wait.h
                __add_wait_queue_entry_tail                     wait.h
                __add_wait_queue_entry_tail_exclusive           wait.h

                TODO: Wait signal pending ...

                If task always waiting, the execution avg. time will be reduce and
                will influence the decision, no necessarily needed to add sleep and wait.

                ------------------
                . Save a specific load with the right shift in the aistats


https://idea.popcount.org/2012-12-11-linux-process-states/
https://elixir.bootlin.com/linux/v4.17.2/source/include/linux/sched.h#L92
Debugging:

        - rescale, Q, dQ, State, Rewards

  	printk("Debug=========================================================\n");
  	printk("Process: %s\n", p->comm);
  	printk("Debug=========================================================\n");

        #include <linux/sched/ai.h>

        #ifdef CONFIG_SCHED_SFS
        	ai_inc(current->se.aistats.sleep_count);
        #endif

Scaled or not scaled, That is the question:

        aistats:
        --------
        u64 scheduled_count     -> not

        u64 state               -> reduced
        u64 old_state;          -> reduced

        u64 avg_runtime;        -> reduced
        u64 runtime_sum;        -> reduced

        u64 avg_block;          -> scaled
        u64 block_count;        -> not

        u64 avg_sleep;          -> scaled
        u64 sleep_count;        -> not

        u64 avg_lock;           -> scaled
        u64 lock_count;         -> not

        u64 di;                 -> NOT USED !!!
        s64 ut;                 -> scaled
        s64 targ;               -> scaled
        s64 q_value;            -> scaled

        ai:
        ---
        s64 dw_load;            -> scaled
        s64 dw_avg_block;       -> scaled
        s64 dw_avg_sleep;       -> scaled
        s64 dw_avg_lock;        -> scaled
        u64 batch_cnt;

        u64 state;              -> reduced
        u64 min_state;          -> reduced

        s64 q_value;            -> scaled
        s64 dq_value;           -> scaled
        s64 old_q_value;        -> scaled

        s64 ut_sum;             -> scaled

        s64 rewards;            -> scaled and reduced

        update_rewards():
        -----------------
        s64 dij                 -> not
        s64 dij2                -> not
        s64 rewards;            -> not
        u64 min_state;          -> not

        update_next():
        --------------
        s64 s                   -> scaled       based on ai->state
        s64 s2                  -> scaled       based on ai->state + avg_runtime
        s64 si                  -> scaled       based on aistats->state
        s64 si2                 -> scaled       based on aistats->state + avg_runtime
        s64 fi_s                -> scaled       based on targ, s and si
        s64 fi_s2               -> scaled       based on targ, s2 and si2

        update_dq(): -> same than for update_next()
        ------------
        s64 s                   -> scaled
        s64 s2                  -> scaled
        s64 si                  -> scaled
        s64 si2;                -> scaled
        s64 fi_s                -> scaled
        s64 fi_s2;              -> scaled

        update_weights():
        -----------------
        s64 update              -> scaled       based on alpha dq_value rewards
                                                         old_q_value gamma
                                                         q_value

        synch_point():
        --------------
        dw_load                 -> scaled
        dw_avg_block            -> scaled
        dw_avg_sleep            -> scaled
        dw_avg_lock             -> scaled
        cpu_cnt                 -> not
